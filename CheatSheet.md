# Cheat Sheet: `float` (IEEEâ€‘754, 32â€‘bit) ğŸ’§

## 1. What `float` actually is ğŸ§®

* A **floatingâ€‘point** type: the value is stored approximately as

  **value = (âˆ’1)^sign Ã— 1.mantissaâ‚‚ Ã— 2^e**

  where `1.mantissaâ‚‚` is the binary significand (mantissa) and `e` is an integer exponent.
* Represents **approximate real numbers**, *not* exact math. Many decimal fractions (0.1, 0.2, 0.3, â€¦) cannot be represented exactly.

---

## 2. Internal layout of a 32â€‘bit `float` ğŸ§±

Total **32 bits**:

* 1 bit â€” **sign** (0 = positive, 1 = negative â•â–)
* 8 bits â€” **exponent** (stored with bias = 127)
* 23 bits â€” **fraction** (fractional part of the mantissa)

Decoded value:

```text
value = (âˆ’1)^sign_bit Ã— 1.fraction_bitsâ‚‚ Ã— 2^(exponent_bits âˆ’ 127)
```

* `1.fraction_bitsâ‚‚` = implicit leading 1 + 23 fractional bits.
* `exponent_bits` is the unsigned value stored in the exponent field.

---

## 3. Range and precision ğŸ¯

* Approximate magnitude range: **from ~1.18Ã—10â»Â³â¸ to ~3.4Ã—10Â³â¸**.
* Precision: about **6â€“7 decimal significant digits**.

ğŸ‘‰ Rule of thumb: `float` is fine for *rough* real numbers, but not for money, highâ€‘precision physics, etc.

---

## 4. Special values âš ï¸

Reserved bit patterns:

* **+0.0 / âˆ’0.0** â€” exponent = 0, fraction = 0, sign decides +0 / âˆ’0.
* **+âˆ / âˆ’âˆ** â€” exponent = 255 (all ones), fraction = 0.
* **NaN** (Not a Number) â€” exponent = 255, fraction â‰  0.

NaN shows up when a result is mathematically â€œundefinedâ€, like `0.0f / 0.0f`.

---

## 5. Typical pitfalls with `float` ğŸª¤

1. **Using `==` for comparison is unsafe in general**

   ```cpp
   float a = 0.1f + 0.2f;
   float b = 0.3f;

   // Bad (might be false due to rounding):
   if (a == b) { /* ... */ }

   // Better:
   if (fabs(a - b) < 1e-6f) { /* ... */ }
   ```

   Many decimal fractions are not exactly representable in binary â†’ tiny rounding errors.

2. **Error accumulation** â±ï¸

   A long sequence of operations can accumulate rounding error.

3. **Overflow and loss of significance** ğŸ’¥

   * Very large results â†’ Â±âˆ.
   * Subtracting nearly equal numbers â†’ loss of significant digits (cancellation).

---

## 6. `float` vs `double` ğŸ†š

* `float`: 32 bits, ~6â€“7 decimal digits of precision.
* `double`: 64 bits, ~15â€“16 decimal digits of precision.

ğŸ‘‰ In most serious numeric code, `double` is preferred; `float` is used when memory/performance really matters (graphics, large arrays, etc.).

---

## 7. Relation to fixedâ€‘point (`Fixed` from C++ Module 02) âš–ï¸

* `float`: mantissa + exponent â†’ the **binary point â€œfloatsâ€**; spacing between representable numbers grows with magnitude.
* fixedâ€‘point: one integer + a fixed number of fractional bits â†’ the **binary point is fixed**; spacing between representable numbers is constant (step = `1 / 2^fractionalBits`).

Think of it like this:

* `float` = scientific notation in base 2.
* fixedâ€‘point = integer grid with a constant step size.

---

# Cheat Sheet: Converting a number to Â±1.xxxâ‚‚ Ã— 2^e ğŸ”„

How to get the **normalized binary form** used conceptually by IEEEâ€‘754.

## 1. Core idea ğŸ’¡

For any nonâ€‘zero finite value:

> **x = (Â±1.xxxâ‚‚) Ã— 2^e**

where the part before the binary point is always exactly `1` (normalized form).

---

## 2. Highâ€‘level algorithm (math view) ğŸ“

### Step 1. Determine the sign

* If `x < 0` â†’ `sign = 1`, work with `|x|`.
* If `x â‰¥ 0` â†’ `sign = 0`.

### Step 2. Convert to binary

Split `x` into integer and fractional parts:

```text
x = N + f, where N is integer, f is fractional (0 â‰¤ f < 1)
```

1. Convert **N** to binary by repeated division by 2, collecting remainders (from bottom to top).
2. Convert **f** to binary by repeatedly multiplying by 2 and recording the integer part (0 or 1) as each next bit after the point.

Result: a binary representation like `â€¦xxx.yyyâ‚‚`.

### Step 3. Normalize to 1.xxxâ‚‚

Move the binary point so that there is exactly one `1` to the left of it.

* Example (larger number):

  * `101.11â‚‚ â†’ 1.0111â‚‚ Ã— 2Â²`
  * We shifted the point **left by 2 positions** â†’ exponent `e = 2`.

* Example (small number):

  * `0.00101â‚‚ â†’ 1.01â‚‚ Ã— 2â»Â³`
  * We shifted the point **right by 3 positions** â†’ exponent `e = âˆ’3`.

Rule of thumb:

* Shift **left by k** â†’ multiply by `2^k`.
* Shift **right by k** â†’ multiply by `2^(âˆ’k)`.

We compensate that shift with the exponent `e`.

### Step 4. Final normalized form âœ…

Write the number as:

```text
x = (Â±1.mantissaâ‚‚) Ã— 2^e
```

where `1.mantissaâ‚‚` is the normalized significand and `e` is the exponent.

---

## 3. Mapping normalized form to IEEEâ€‘754 `float` ğŸ§¾

Once we have `x = (Â±1.mantissaâ‚‚) Ã— 2^e`, we build the actual `float` fields:

1. **Sign bit**:

   * 0 if `x â‰¥ 0`,
   * 1 if `x < 0`.

2. **Exponent field (8 bits)**:

   * `exponent_bits = e + 127` (for 32â€‘bit float, bias = 127).

3. **Fraction field (23 bits)**:

   * store only the fractional part of the mantissa (bits after the `1.`),
   * pad with zeros if fewer than 23 bits,
   * round if more than 23 bits.

Decoding formula:

```text
value = (âˆ’1)^sign_bit Ã— 1.fraction_bitsâ‚‚ Ã— 2^(exponent_bits âˆ’ 127)
```

---

## 4. Miniâ€‘example (5.75) ğŸ§Š

1. Decimal to binary:

   * 5.75â‚â‚€ = 101.11â‚‚
2. Normalize:

   * `101.11â‚‚ â†’ 1.0111â‚‚ Ã— 2Â²` â†’ mantissa = `1.0111â‚‚`, exponent `e = 2`.
3. Sign:

   * `sign_bit = 0` (positive).
4. Exponent bits:

   * `exponent_bits = e + 127 = 2 + 127 = 129` â†’ `10000001â‚‚`.
5. Fraction bits:

   * fractional part = `0111`, padded to 23 bits: `01110000000000000000000`.

Final IEEEâ€‘754 layout:

```text
sign      exponent        fraction
0         10000001        01110000000000000000000
```

This bit pattern is exactly `5.75f` in memory ğŸ’¾.
